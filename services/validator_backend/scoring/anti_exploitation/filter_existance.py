from transformers import AutoTokenizer, AutoModelForCausalLM, DynamicCache
from typing import List
import random
from semantic_text_splitter import TextSplitter
from copy import deepcopy
from datasets import load_dataset
from typing import Tuple
from ..utils import generate_answer
import re


class FilterExistanceChecker:
    def __init__(self):
        self.splitter = TextSplitter(256)
        self.negative_dataset = self._load_negative_dataset()

    def _load_negative_dataset(self):
        negative_dataset = load_dataset(
            "TIGER-Lab/Fineweb-Instruct", streaming=True, split="train"
        )
        negative_dataset = negative_dataset.shuffle()
        negative_dataset = negative_dataset.filter(lambda x: len(x["response"]) > 100)
        negative_dataset = negative_dataset.map(lambda x: {"text": x["response"]})
        negative_dataset = iter(negative_dataset)
        return negative_dataset

    def _get_negative_message(self):
        try:
            return next(self.negative_dataset)["text"]
        except StopIteration:
            self.negative_dataset = self._load_negative_dataset()
            return self._get_negative_message()

    def _check_text_exists(
        self,
        tokenizer: AutoTokenizer,
        model: AutoModelForCausalLM,
        kv_cache: DynamicCache,
        query_chunk: str,
        context_length: int,
    ) -> bool:
        _kv_cache = deepcopy(kv_cache)
        prompt = f"\n\n You are a precise fact checker. Given the previous context, determine if the following quote appears in or is directly paraphrased from the provided information. Answer with EXACTLY 'yes' or 'no'. Quote:\n```\n{query_chunk}\n```\n [/INST]"
        prompt_ids = tokenizer.encode(
            prompt,
            return_tensors="pt",
            add_special_tokens=False,
        )
        completion_text = generate_answer(
            model=model,
            tokenizer=tokenizer,
            question_ids=prompt_ids,
            cache=_kv_cache,
            context_length=context_length,
            max_new_tokens=10,
        )
        print(f"Filter Completion: {completion_text}")
        # Split response into words and clean up
        words = re.findall(r"\b\w+\b", completion_text.lower())
        return "yes" in words, "no" in words or "not" in words

    def get_messages_pair(self, messages: List[dict]) -> Tuple[str, str]:
        # Test on positive case (text from conversation)
        contents = [msg["content"] for msg in messages]
        random_message = random.choice(contents)
        chunks = self.splitter.chunks(random_message)
        positive_chunk = random.choice(chunks)
        # Test on negative case (text not from conversation)
        negative_chunk = random.choice(
            self.splitter.chunks(self._get_negative_message())
        )
        return positive_chunk, negative_chunk

    def filter_existance(
        self,
        tokenizer: AutoTokenizer,
        model: AutoModelForCausalLM,
        kv_cache: DynamicCache,
        positive_chunks: List[str],
        negative_chunks: List[str],
        context_length: int,
    ) -> bool:
        for positive_chunk in positive_chunks:
            exist_yes, exist_no = self._check_text_exists(
                tokenizer, model, kv_cache, positive_chunk, context_length
            )
            if not exist_yes or (exist_yes and exist_no):
                return False

        # Test on negative case (text not from conversation)
        for negative_chunk in negative_chunks:
            exist_yes, exists_no = self._check_text_exists(
                tokenizer, model, kv_cache, negative_chunk, context_length
            )
            if not exists_no or (exist_yes and exists_no):
                return False

        return True
